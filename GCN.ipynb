{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "from time import perf_counter\n",
    "from sklearn.metrics.pairwise import distance_metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from numpy import linalg as LA\n",
    "from time import perf_counter\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"\n",
    "    A Graph Convolution Layer (GCN)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.W = nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        stdv = 1. / math.sqrt(self.W.weight.size(1))\n",
    "        self.W.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, adj):       \n",
    "        support = self.W(x)\n",
    "        output = torch.spmm(adj, support)\n",
    "        return output\n",
    "        \n",
    "\n",
    "class GCN(nn.Module):\n",
    "    \"\"\"\n",
    "    A Two-layer GCN.\n",
    "    \"\"\"\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, n_ways)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj, use_relu=True):\n",
    "        x = self.gc1(x, adj)\n",
    "        if use_relu:\n",
    "            x = F.relu(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x\n",
    "    \n",
    "def get_model(model_opt, nfeat, nclass, nhid=0, dropout=0, cuda=True):\n",
    "    if model_opt == \"GCN\":\n",
    "        model = GCN(nfeat=nfeat,\n",
    "                    nhid=nhid,\n",
    "                    nclass=nclass,\n",
    "                    dropout=dropout)\n",
    "    else:\n",
    "        raise NotImplementedError('model:{} is not implemented!'.format(model_opt))\n",
    "\n",
    "    if cuda: model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file, data):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints/miniImagenet/WideResNet28_10_S2M2_R/last'\n",
    "out_dict = load_pickle(save_dir + '/output.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_case(ld_dict, shot, n_ways, n_queries):\n",
    "    sample_class = random.sample(list(ld_dict.keys()), n_ways)\n",
    "    train_input = []\n",
    "    test_input = []\n",
    "    for each_class in sample_class:\n",
    "        samples = random.sample(ld_dict[each_class], shot + n_queries)\n",
    "        train_input += samples[:shot]\n",
    "        test_input += samples[shot:]\n",
    "    train_input = np.array(train_input).astype(np.float32)\n",
    "    test_input = np.array(test_input).astype(np.float32)\n",
    "    return train_input, test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(train_data, test_data, k, alpha, kappa):\n",
    "    eps = np.finfo(float).eps\n",
    "    emb_all = np.append(train_data, test_data, axis=0)\n",
    "    N = emb_all.shape[0]\n",
    "    metric = distance_metrics()['cosine']\n",
    "    S = 1 - metric(emb_all, emb_all)\n",
    "    S = torch.tensor(S)\n",
    "    S = S - torch.eye(S.shape[0])\n",
    "    \n",
    "    if k>0:\n",
    "        topk, indices = torch.topk(S, k)\n",
    "        mask = torch.zeros_like(S)\n",
    "        mask = mask.scatter(1, indices, 1)\n",
    "        mask = ((mask+torch.t(mask))>0).type(torch.float32)       \n",
    "        S    = S*mask \n",
    "    \n",
    "    D       = S.sum(0)\n",
    "    Dnorm   = torch.diag(torch.pow(D, -0.5))\n",
    "    E   = torch.matmul(Dnorm,torch.matmul(S, Dnorm))\n",
    "\n",
    "    E = alpha * torch.eye(E.shape[0]) + E\n",
    "    E = torch.matrix_power(E, kappa)\n",
    "    E = E.cuda()\n",
    "    \n",
    "    train_data = train_data - train_data.mean(0)\n",
    "    train_data_norm = train_data / LA.norm(train_data, 2, 1)[:, None]\n",
    "    test_data = test_data - test_data.mean(0)\n",
    "    test_data_norm = test_data / LA.norm(test_data, 2, 1)[:, None]\n",
    "    features = np.append(train_data_norm, test_data_norm, axis=0)\n",
    "    \n",
    "    #features = np.append(train_data, test_data, axis=0)\n",
    "    features = torch.tensor(features).cuda()\n",
    "    return E, features\n",
    "\n",
    "def get_labels(n_ways, shot, n_queries):\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    classes = [i for i in range(n_ways)]\n",
    "    for each_class in classes:\n",
    "        train_labels += [each_class] * shot\n",
    "        test_labels += [each_class] * n_queries\n",
    "\n",
    "    train_labels = torch.tensor(train_labels).cuda()\n",
    "    test_labels = torch.tensor(test_labels).cuda()\n",
    "    return train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence_interval(data):\n",
    "    \"\"\"\n",
    "    Compute 95% confidence interval\n",
    "    :param data: An array of mean accuracy (or mAP) across a number of sampled episodes.\n",
    "    :return: the 95% confidence interval for this data.\n",
    "    \"\"\"\n",
    "    a = 1.0 * np.array(data)\n",
    "    m = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    pm = 1.96 * (std / np.sqrt(len(a)))\n",
    "    return m, pm\n",
    "\n",
    "def train_regression(model, features, shot, n_ways, train_labels, E, epochs=100, weight_decay=5e-6, lr=0.2):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    accs = []\n",
    "    #t = perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features, E)\n",
    "        loss_train = F.cross_entropy(output[:shot*n_ways,], train_labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    #train_time = perf_counter()-t\n",
    "    return model\n",
    "\n",
    "def test_regression(model, features, shot, n_ways, test_labels, E):\n",
    "    model.eval()\n",
    "    output = model(features, E)\n",
    "    return accuracy(output[shot*n_ways:,], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sgc(out_dict, shot, n_ways, n_queries, ite=10000, epochs=1000, weight_decay=5e-6, lr=0.001, dropout=0):\n",
    "    accs = []\n",
    "    for i in range(ite):\n",
    "        train_data, test_data = sample_case(out_dict, shot, n_ways, n_queries)\n",
    "        E, features = get_adj(train_data, test_data, k=10, alpha=0.5, kappa=3)\n",
    "        train_labels, test_labels = get_labels(n_ways, shot, n_queries)\n",
    "        model_sgc = get_model(model_opt=\"GCN\", nfeat=features.size(1), nclass=n_ways, nhid=1024, dropout=0, cuda=True)\n",
    "        model_sgc = train_regression(model_sgc, features, shot, n_ways, train_labels, E=E, epochs=epochs, weight_decay=weight_decay, lr=lr)\n",
    "        acc_test = test_regression(model_sgc, features, shot, n_ways, test_labels, E)\n",
    "        accs.append(acc_test)\n",
    "        \n",
    "    accs = torch.stack(accs).cpu().detach().numpy()\n",
    "    acc_mean, acc_conf = compute_confidence_interval(accs)\n",
    "    return acc_mean, acc_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Test: LAST\n",
      "GVP 1Shot\t0.7067(0.0000)\n"
     ]
    }
   ],
   "source": [
    "n_ways = 5\n",
    "n_queries = 15\n",
    "accuracy_info_shot1_GCN = test_sgc(out_dict=out_dict, shot=1, n_ways=n_ways, n_queries=n_queries)\n",
    "print('Meta Test: LAST\\n{}\\t{:.4f}({:.4f})'.format(\n",
    "            'GVP 1Shot', *accuracy_info_shot1_GCN))\n",
    "#accuracy_info_shot5_GCN = test_sgc(out_dict=out_dict, shot=5, n_ways=args.meta_val_way, n_queries=args.meta_val_query, degree=2)\n",
    "#print('Meta Test: LAST\\n{}\\t{:.4f}({:.4f})\\t{:.4f}'.format(\n",
    "#            'GVP 5Shot', *accuracy_info_shot5_GCN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
