{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.metrics.pairwise import distance_metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from numpy import linalg as LA\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGC(nn.Module):\n",
    "    \"\"\"\n",
    "    A Simple PyTorch Implementation of Logiistic Regression.\n",
    "    Assuming the features have been preprocessed with k-step graph propagation.\n",
    "    \"\"\"\n",
    "    def __init__(self, nfeat, nclass):\n",
    "        super(SGC, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(nfeat, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.W(x)\n",
    "\n",
    "    \n",
    "def get_model(model_opt, nfeat, nclass, cuda=True):\n",
    "    if model_opt == \"SGC\":\n",
    "        model = SGC(nfeat=nfeat,\n",
    "                    nclass=nclass)\n",
    "    else:\n",
    "        raise NotImplementedError('model:{} is not implemented!'.format(model_opt))\n",
    "\n",
    "    if cuda: model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file, data):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './checkpoints/miniImagenet/WideResNet28_10_S2M2_R/last'\n",
    "#save_dir = './checkpoints/miniImagenet/ResNet18_S2M2_R/last'\n",
    "out_dict = load_pickle(save_dir + '/output.plk')\n",
    "out_dict_aug = load_pickle(save_dir + '/output_aug.plk')\n",
    "#out_dict_aug_180 = load_pickle(save_dir + '/output_aug_180.plk')\n",
    "#out_dict_aug_270 = load_pickle(save_dir + '/output_aug_270.plk')\n",
    "out_dicts_aug = [out_dict_aug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_case(ld_dict, ld_dict_aug, shot, n_ways, n_queries):\n",
    "    sample_class = random.sample(list(ld_dict.keys()), n_ways)\n",
    "    \n",
    "    train_input = []\n",
    "    test_input = []\n",
    "    train_input_aug = []\n",
    "    test_input_aug = []\n",
    "    \n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    train_labels_aug = []\n",
    "    test_labels_aug = []\n",
    "    \n",
    "    class_num = 0\n",
    "    \n",
    "    for each_class in sample_class:\n",
    "        index = random.sample([i for i in range(600)], shot+n_queries)\n",
    "        samples = np.array(ld_dict[each_class])[index].tolist()\n",
    "        samples_aug = np.array(ld_dict_aug[each_class])[index].tolist()\n",
    "        \n",
    "        train_input += samples[:shot]\n",
    "        train_input_aug += samples_aug[:shot]\n",
    "        test_input += samples[shot:]\n",
    "        #test_input_aug += samples_aug[shot:]\n",
    "        \n",
    "        train_labels += [class_num] * shot\n",
    "        train_labels_aug += [class_num] * shot\n",
    "        test_labels += [class_num] * n_queries\n",
    "        #test_labels_aug += [class_num] * n_queries\n",
    "        \n",
    "        class_num += 1\n",
    "        \n",
    "    train_input = np.array(train_input+train_input_aug).astype(np.float32)\n",
    "    test_input = np.array(test_input+test_input_aug).astype(np.float32)\n",
    "    train_labels = torch.tensor(train_labels+train_labels_aug).cuda()\n",
    "    test_labels = torch.tensor(test_labels+test_labels_aug).cuda()\n",
    "    return train_input, test_input, train_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 640)\n",
      "(75, 640)\n",
      "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_input, test_input, train_labels, test_labels = sample_case(out_dict, out_dicts_aug[0], shot=1, n_ways=5, n_queries=15)\n",
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(train_data, test_data, k, alpha, kappa):\n",
    "    eps = np.finfo(float).eps\n",
    "    emb_all = np.append(train_data, test_data, axis=0)\n",
    "    N = emb_all.shape[0]\n",
    "    metric = distance_metrics()['cosine']\n",
    "    S = 1 - metric(emb_all, emb_all)\n",
    "    S = torch.tensor(S)\n",
    "    S = S - torch.eye(S.shape[0])\n",
    "    \n",
    "    # k plus proche voisin\n",
    "    if k>0:\n",
    "        topk, indices = torch.topk(S, k)\n",
    "        mask = torch.zeros_like(S)\n",
    "        mask = mask.scatter(1, indices, 1)\n",
    "        mask = ((mask+torch.t(mask))>0).type(torch.float32)\n",
    "        S    = S*mask \n",
    "    \n",
    "    D       = S.sum(0)\n",
    "    Dnorm   = torch.diag(torch.pow(D, -0.5))\n",
    "    E   = torch.matmul(Dnorm,torch.matmul(S, Dnorm))\n",
    "\n",
    "    E = alpha * torch.eye(E.shape[0]) + E\n",
    "    E = torch.matrix_power(E, kappa)\n",
    "    \n",
    "    E = E.cuda()\n",
    "    \n",
    "    train_data = train_data - train_data.mean(0)\n",
    "    train_data_norm = train_data / LA.norm(train_data, 2, 1)[:, None]\n",
    "    test_data = test_data - test_data.mean(0)\n",
    "    test_data_norm = test_data / LA.norm(test_data, 2, 1)[:, None]\n",
    "    features = np.append(train_data_norm, test_data_norm, axis=0)\n",
    "    \n",
    "    #features = np.append(train_data, test_data, axis=0)\n",
    "    features = torch.tensor(features).cuda()\n",
    "    return E, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 85])\n",
      "torch.Size([85, 640])\n"
     ]
    }
   ],
   "source": [
    "E, features = get_adj(train_input, test_input, k=10, alpha=0.5, kappa=3)\n",
    "print(E.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def compute_confidence_interval(data):\n",
    "    \"\"\"\n",
    "    Compute 95% confidence interval\n",
    "    :param data: An array of mean accuracy (or mAP) across a number of sampled episodes.\n",
    "    :return: the 95% confidence interval for this data.\n",
    "    \"\"\"\n",
    "    a = 1.0 * np.array(data)\n",
    "    m = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    pm = 1.96 * (std / np.sqrt(len(a)))\n",
    "    return m, pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgc_precompute(features, adj, degree):\n",
    "    for i in range(degree):\n",
    "        features = torch.spmm(adj, features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(model,\n",
    "                     train_features, train_labels,\n",
    "                     epochs=100, weight_decay=5e-6,\n",
    "                     lr=0.2):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    accs = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_features)\n",
    "        loss_train = F.cross_entropy(output, train_labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model\n",
    "\n",
    "def test_regression(model, test_features, test_labels):\n",
    "    model.eval()\n",
    "    return accuracy(model(test_features), test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sgc(out_dict, shot, n_ways, n_queries, k, ite=10000, epochs=1000, degree=1, weight_decay=5e-6, lr=0.001):\n",
    "    accs = []\n",
    "    for i in range(ite):\n",
    "        train_data, test_data, train_labels, test_labels = sample_case(out_dict, out_dicts_aug[0], shot, n_ways, n_queries)\n",
    "        E, features = get_adj(train_data, test_data, k=k, alpha=0.5, kappa=3)\n",
    "        model_sgc = get_model(model_opt=\"SGC\", nfeat=features.size(1), nclass=n_ways, cuda=True)\n",
    "        features = sgc_precompute(features, E, degree)\n",
    "        model_sgc = train_regression(model_sgc, features[:n_ways*shot*2,], train_labels,\n",
    "                 epochs=epochs, weight_decay=weight_decay, lr=lr)\n",
    "        acc_test = test_regression(model_sgc, features[n_ways*shot*2:,], test_labels)\n",
    "        accs.append(acc_test)\n",
    "        \n",
    "    accs = torch.stack(accs).cpu().detach().numpy()\n",
    "    acc_mean, acc_conf = compute_confidence_interval(accs)\n",
    "    return acc_mean, acc_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Test: LAST\n",
      "GVP shot1\t0.7568(0.0023)\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n_ways = 5\n",
    "n_queries = 15\n",
    "accuracy_info_shot1 = test_sgc(out_dict=out_dict, shot=1, n_ways=n_ways, n_queries=n_queries, k=k)\n",
    "print('Meta Test: LAST\\n{}\\t{:.4f}({:.4f})'.format('GVP shot1', *accuracy_info_shot1))\n",
    "#accuracy_info_shot5 = test_sgc(out_dict=out_dict, shot=5, n_ways=n_ways, n_queries=n_queries, k=k)\n",
    "#print('Meta Test: LAST\\n{}\\t{:.4f}({:.4f})'.format('GVP shot5', *accuracy_info_shot5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
