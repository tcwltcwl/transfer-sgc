{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.metrics.pairwise import distance_metrics\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from numpy import linalg as LA\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGC(nn.Module):\n",
    "    \"\"\"\n",
    "    A Simple PyTorch Implementation of Logiistic Regression.\n",
    "    Assuming the features have been preprocessed with k-step graph propagation.\n",
    "    \"\"\"\n",
    "    def __init__(self, nfeat, nclass):\n",
    "        super(SGC, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(nfeat, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.W(x)\n",
    "\n",
    "    \n",
    "def get_model(model_opt, nfeat, nclass, cuda=True):\n",
    "    if model_opt == \"SGC\":\n",
    "        model = SGC(nfeat=nfeat,\n",
    "                    nclass=nclass)\n",
    "    else:\n",
    "        raise NotImplementedError('model:{} is not implemented!'.format(model_opt))\n",
    "\n",
    "    if cuda: model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file, data):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './checkpoints/miniImagenet/ResNet18_S2M2_R/last'\n",
    "#save_dir = './checkpoints/miniImagenet/ResNet18_S2M2_R/last'\n",
    "out_dict = load_pickle(save_dir + '/output.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_case(ld_dict, shot, n_ways, n_queries):\n",
    "    sample_class = random.sample(list(ld_dict.keys()), n_ways)\n",
    "    train_input = []\n",
    "    test_input = []\n",
    "    \n",
    "    for each_class in sample_class:\n",
    "        samples = random.sample(ld_dict[each_class], shot + n_queries)\n",
    "        train_input += samples[:shot]\n",
    "        test_input += samples[shot:]\n",
    "    train_input = np.array(train_input).astype(np.float32)\n",
    "    test_input = np.array(test_input).astype(np.float32)\n",
    "    return train_input, test_input\n",
    "\n",
    "def get_labels(n_ways, shot, n_queries):\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    classes = [i for i in range(n_ways)]\n",
    "    for each_class in classes:\n",
    "        train_labels += [each_class] * shot\n",
    "        test_labels += [each_class] * n_queries\n",
    "    train_labels = torch.tensor(train_labels).cuda()\n",
    "    test_labels = torch.tensor(test_labels).cuda()\n",
    "    return train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 512)\n",
      "(75, 512)\n",
      "tensor([0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_ways = 5\n",
    "shot = 1\n",
    "n_queries = 15\n",
    "train_data, test_data = sample_case(out_dict, shot=shot, n_ways=n_ways, n_queries=n_queries)\n",
    "train_labels, test_labels = get_labels(n_ways=n_ways, shot=shot, n_queries=n_queries)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(train_data, test_data, k, alpha, kappa):\n",
    "    eps = np.finfo(float).eps\n",
    "    emb_all = np.append(train_data, test_data, axis=0)\n",
    "    N = emb_all.shape[0]\n",
    "    metric = distance_metrics()['cosine']\n",
    "    S = 1 - metric(emb_all, emb_all)\n",
    "    S = torch.tensor(S)\n",
    "    S = S - torch.eye(S.shape[0])\n",
    "    \n",
    "    # k plus proche voisin\n",
    "    if k>0:\n",
    "        topk, indices = torch.topk(S, k)\n",
    "        mask = torch.zeros_like(S)\n",
    "        mask = mask.scatter(1, indices, 1)\n",
    "        mask = ((mask+torch.t(mask))>0).type(torch.float32)\n",
    "        S    = S*mask \n",
    "    \n",
    "    D       = S.sum(0)\n",
    "    Dnorm   = torch.diag(torch.pow(D, -0.5))\n",
    "    E   = torch.matmul(Dnorm,torch.matmul(S, Dnorm))\n",
    "\n",
    "    E = alpha * torch.eye(E.shape[0]) + E\n",
    "    E = torch.matrix_power(E, kappa)\n",
    "    \n",
    "    E = E.cuda()\n",
    "    \n",
    "    train_data = train_data - train_data.mean(0)\n",
    "    train_data_norm = train_data / LA.norm(train_data, 2, 1)[:, None]\n",
    "    test_data = test_data - test_data.mean(0)\n",
    "    test_data_norm = test_data / LA.norm(test_data, 2, 1)[:, None]\n",
    "    features = np.append(train_data_norm, test_data_norm, axis=0)\n",
    "    \n",
    "    #features = np.append(train_data, test_data, axis=0)\n",
    "    features = torch.tensor(features).cuda()\n",
    "    return E, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 80])\n",
      "torch.Size([80, 512])\n"
     ]
    }
   ],
   "source": [
    "E, features = get_adj(train_data, test_data, k=10, alpha=0.5, kappa=3)\n",
    "print(E.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def compute_confidence_interval(data):\n",
    "    \"\"\"\n",
    "    Compute 95% confidence interval\n",
    "    :param data: An array of mean accuracy (or mAP) across a number of sampled episodes.\n",
    "    :return: the 95% confidence interval for this data.\n",
    "    \"\"\"\n",
    "    a = 1.0 * np.array(data)\n",
    "    m = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    pm = 1.96 * (std / np.sqrt(len(a)))\n",
    "    return m, pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgc_precompute(features, adj, degree):\n",
    "    for i in range(degree):\n",
    "        features = torch.spmm(adj, features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression(model,\n",
    "                     train_features, train_labels,\n",
    "                     epochs=100, weight_decay=5e-6,\n",
    "                     lr=0.2):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "    accs = []\n",
    "    t = perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_features)\n",
    "        loss_train = F.cross_entropy(output, train_labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_time = perf_counter()-t\n",
    "    return model\n",
    "\n",
    "def test_regression(model, test_features, test_labels):\n",
    "    model.eval()\n",
    "    return accuracy(model(test_features), test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sgc(out_dict, shot, n_ways, n_queries, k, ite=600, epochs=1000, degree=1, weight_decay=5e-6, lr=0.001):\n",
    "    accs = []\n",
    "    for i in range(ite):\n",
    "        train_data, test_data = sample_case(out_dict, shot, n_ways, n_queries)\n",
    "        E, features = get_adj(train_data, test_data, k=k, alpha=0.5, kappa=3)\n",
    "        train_labels, test_labels = get_labels(n_ways, shot, n_queries)\n",
    "        model_sgc = get_model(model_opt=\"SGC\", nfeat=features.size(1), nclass=n_ways, cuda=True)\n",
    "        features = sgc_precompute(features, E, degree)\n",
    "        model_sgc = train_regression(model_sgc, features[:n_ways*shot,], train_labels,\n",
    "                 epochs=epochs, weight_decay=weight_decay, lr=lr)\n",
    "        acc_test = test_regression(model_sgc, features[n_ways*shot:,], test_labels)\n",
    "        accs.append(acc_test)\n",
    "        \n",
    "    accs = torch.stack(accs).cpu().detach().numpy()\n",
    "    acc_mean, acc_conf = compute_confidence_interval(accs)\n",
    "    return acc_mean, acc_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Test: LAST\n",
      "GVP shot1\t0.8800(0.0000)\t0.6460\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "accuracy_info_shot1 = test_sgc(out_dict=out_dict, shot=1, n_ways=n_ways, n_queries=n_queries, k=k)\n",
    "print('Meta Test: LAST\\n{}\\t{:.4f}({:.4f})\\t{:.4f}'.format('GVP shot1', *accuracy_info_shot1))\n",
    "#accuracy_info_shot5 = test_sgc(out_dict=out_dict, shot=5, n_ways=n_ways, n_queries=n_queries, k=k)\n",
    "#print('Meta Test: LAST\\n{}\\t{:.4f}({:.4f})'.format('GVP shot5', *accuracy_info_shot5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
